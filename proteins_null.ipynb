{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15febec9-b2e3-4ac7-ae22-72d4acf1dc8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import functools\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "import jraph\n",
    "import flax\n",
    "import haiku as hk\n",
    "import optax\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from ogb.nodeproppred import Evaluator, PygNodePropPredDataset\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import pathlib\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f61b7c63-4eb9-4c8d-89a9-3381d637dbd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = PygNodePropPredDataset(name = 'ogbn-proteins', root='/data101/makinen/ogbn/')\n",
    "splitted_idx = dataset.get_idx_split()\n",
    "data = dataset[0]\n",
    "data.node_species = None\n",
    "data.y = data.y.to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28118a3b-4045-4c7a-a1fb-4066fb29c346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import RandomNodeLoader\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "\n",
    "row, col = data.edge_index\n",
    "data.x = scatter(data.edge_attr, col, dim_size=data.num_nodes, reduce='sum')\n",
    "\n",
    "# Set split indices to masks.\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    mask[splitted_idx[split]] = True\n",
    "    data[f'{split}_mask'] = mask\n",
    "\n",
    "train_reader = RandomNodeLoader(data, num_parts=200, shuffle=True,\n",
    "                                num_workers=0)\n",
    "test_reader = RandomNodeLoader(data, num_parts=5, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7cfd7-15ba-4207-9edb-1b1f567a5f63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0001: 100%|██████████| 40/40 [00:53<00:00,  1.35s/it]\n",
      "Evaluating epoch: 0001: 100%|██████████| 5/5 [00:36<00:00,  7.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3760, Train: 0.6770, Val: 0.5920, Test: 0.5667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0002: 100%|██████████| 40/40 [00:54<00:00,  1.35s/it]\n",
      "Evaluating epoch: 0002: 100%|██████████| 5/5 [00:34<00:00,  6.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3273, Train: 0.7118, Val: 0.6967, Test: 0.6436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0003: 100%|██████████| 40/40 [00:54<00:00,  1.35s/it]\n",
      "Evaluating epoch: 0003: 100%|██████████| 5/5 [00:34<00:00,  6.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3157, Train: 0.7329, Val: 0.7118, Test: 0.6762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0004: 100%|██████████| 40/40 [00:53<00:00,  1.35s/it]\n",
      "Evaluating epoch: 0004: 100%|██████████| 5/5 [00:34<00:00,  6.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3088, Train: 0.7513, Val: 0.7375, Test: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0005: 100%|██████████| 40/40 [00:53<00:00,  1.34s/it]\n",
      "Evaluating epoch: 0005: 100%|██████████| 5/5 [00:34<00:00,  6.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3052, Train: 0.7643, Val: 0.7458, Test: 0.6963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0006: 100%|██████████| 40/40 [00:53<00:00,  1.34s/it]\n",
      "Evaluating epoch: 0006: 100%|██████████| 5/5 [00:34<00:00,  6.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2990, Train: 0.7808, Val: 0.7678, Test: 0.6955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0007: 100%|██████████| 40/40 [00:53<00:00,  1.33s/it]\n",
      "Evaluating epoch: 0007: 100%|██████████| 5/5 [00:34<00:00,  6.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2935, Train: 0.7856, Val: 0.7698, Test: 0.6932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0008: 100%|██████████| 40/40 [00:53<00:00,  1.34s/it]\n",
      "Evaluating epoch: 0008: 100%|██████████| 5/5 [00:34<00:00,  6.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2924, Train: 0.7853, Val: 0.7758, Test: 0.7016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0009: 100%|██████████| 40/40 [00:53<00:00,  1.34s/it]\n",
      "Evaluating epoch: 0009: 100%|██████████| 5/5 [00:34<00:00,  6.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2881, Train: 0.7969, Val: 0.7844, Test: 0.7105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0010: 100%|██████████| 40/40 [00:54<00:00,  1.35s/it]\n",
      "Evaluating epoch: 0010: 100%|██████████| 5/5 [00:34<00:00,  6.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2869, Train: 0.7975, Val: 0.7850, Test: 0.7161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0011: 100%|██████████| 40/40 [00:53<00:00,  1.34s/it]\n",
      "Evaluating epoch: 0011: 100%|██████████| 5/5 [00:34<00:00,  6.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2829, Train: 0.8003, Val: 0.7903, Test: 0.7171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0012: 100%|██████████| 40/40 [00:54<00:00,  1.36s/it]\n",
      "Evaluating epoch: 0012: 100%|██████████| 5/5 [00:34<00:00,  6.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2827, Train: 0.8036, Val: 0.7835, Test: 0.7232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0013: 100%|██████████| 40/40 [00:54<00:00,  1.35s/it]\n",
      "Evaluating epoch: 0013: 100%|██████████| 5/5 [00:34<00:00,  6.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2807, Train: 0.8050, Val: 0.7879, Test: 0.7248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0014: 100%|██████████| 40/40 [00:53<00:00,  1.34s/it]\n",
      "Evaluating epoch: 0014: 100%|██████████| 5/5 [00:34<00:00,  6.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2765, Train: 0.8167, Val: 0.7910, Test: 0.7266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0015: 100%|██████████| 40/40 [00:54<00:00,  1.35s/it]\n",
      "Evaluating epoch: 0015: 100%|██████████| 5/5 [00:34<00:00,  6.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2739, Train: 0.8170, Val: 0.7926, Test: 0.7034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0016: 100%|██████████| 40/40 [00:53<00:00,  1.34s/it]\n",
      "Evaluating epoch: 0016: 100%|██████████| 5/5 [00:34<00:00,  6.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2747, Train: 0.8137, Val: 0.7951, Test: 0.7278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0017: 100%|██████████| 40/40 [00:53<00:00,  1.34s/it]\n",
      "Evaluating epoch: 0017: 100%|██████████| 5/5 [00:35<00:00,  7.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2725, Train: 0.8128, Val: 0.7887, Test: 0.7092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0018: 100%|██████████| 40/40 [00:53<00:00,  1.34s/it]\n",
      "Evaluating epoch: 0018: 100%|██████████| 5/5 [00:34<00:00,  6.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2703, Train: 0.8259, Val: 0.7893, Test: 0.7240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0019: 100%|██████████| 40/40 [00:53<00:00,  1.34s/it]\n",
      "Evaluating epoch: 0019:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from ogb.nodeproppred import Evaluator, PygNodePropPredDataset\n",
    "from torch.nn import LayerNorm, Linear, ReLU\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.loader import RandomNodeLoader\n",
    "from torch_geometric.nn import DeepGCNLayer, GENConv\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "dataset = PygNodePropPredDataset('ogbn-proteins', root='/data101/makinen/ogbn/')\n",
    "splitted_idx = dataset.get_idx_split()\n",
    "data = dataset[0]\n",
    "data.node_species = None\n",
    "data.y = data.y.to(torch.float)\n",
    "\n",
    "# Initialize features of nodes by aggregating edge features.\n",
    "row, col = data.edge_index\n",
    "data.x = scatter(data.edge_attr, col, dim_size=data.num_nodes, reduce='sum')\n",
    "\n",
    "# Set split indices to masks.\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    mask[splitted_idx[split]] = True\n",
    "    data[f'{split}_mask'] = mask\n",
    "\n",
    "train_loader = RandomNodeLoader(data, num_parts=40, shuffle=True,\n",
    "                                num_workers=5)\n",
    "test_loader = RandomNodeLoader(data, num_parts=5, num_workers=5)\n",
    "\n",
    "\n",
    "class DeeperGCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.node_encoder = Linear(data.x.size(-1), hidden_channels)\n",
    "        self.edge_encoder = Linear(data.edge_attr.size(-1), hidden_channels)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(1, num_layers + 1):\n",
    "            conv = GENConv(hidden_channels, hidden_channels, aggr='softmax',\n",
    "                           t=1.0, learn_t=True, num_layers=2, norm='layer')\n",
    "            norm = LayerNorm(hidden_channels, elementwise_affine=True)\n",
    "            act = ReLU(inplace=True)\n",
    "\n",
    "            layer = DeepGCNLayer(conv, norm, act, block='res+', dropout=0.1,\n",
    "                                 ckpt_grad=i % 3)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, data.y.size(-1))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.node_encoder(x)\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "\n",
    "        x = self.layers[0].conv(x, edge_index, edge_attr)\n",
    "\n",
    "        for layer in self.layers[1:]:\n",
    "            x = layer(x, edge_index, edge_attr)\n",
    "\n",
    "        x = self.layers[0].act(self.layers[0].norm(x))\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DeeperGCN(hidden_channels=64, num_layers=28).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "evaluator = Evaluator('ogbn-proteins')\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(total=len(train_loader))\n",
    "    pbar.set_description(f'Training epoch: {epoch:04d}')\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.edge_attr)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * int(data.train_mask.sum())\n",
    "        total_examples += int(data.train_mask.sum())\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    y_true = {'train': [], 'valid': [], 'test': []}\n",
    "    y_pred = {'train': [], 'valid': [], 'test': []}\n",
    "\n",
    "    pbar = tqdm(total=len(test_loader))\n",
    "    pbar.set_description(f'Evaluating epoch: {epoch:04d}')\n",
    "\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "        for split in y_true.keys():\n",
    "            mask = data[f'{split}_mask']\n",
    "            y_true[split].append(data.y[mask].cpu())\n",
    "            y_pred[split].append(out[mask].cpu())\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    train_rocauc = evaluator.eval({\n",
    "        'y_true': torch.cat(y_true['train'], dim=0),\n",
    "        'y_pred': torch.cat(y_pred['train'], dim=0),\n",
    "    })['rocauc']\n",
    "\n",
    "    valid_rocauc = evaluator.eval({\n",
    "        'y_true': torch.cat(y_true['valid'], dim=0),\n",
    "        'y_pred': torch.cat(y_pred['valid'], dim=0),\n",
    "    })['rocauc']\n",
    "\n",
    "    test_rocauc = evaluator.eval({\n",
    "        'y_true': torch.cat(y_true['test'], dim=0),\n",
    "        'y_pred': torch.cat(y_pred['test'], dim=0),\n",
    "    })['rocauc']\n",
    "\n",
    "    return train_rocauc, valid_rocauc, test_rocauc\n",
    "\n",
    "\n",
    "for epoch in range(1, 1001):\n",
    "    loss = train(epoch)\n",
    "    train_rocauc, valid_rocauc, test_rocauc = test()\n",
    "    print(f'Loss: {loss:.4f}, Train: {train_rocauc:.4f}, '\n",
    "          f'Val: {valid_rocauc:.4f}, Test: {test_rocauc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d3a863-04e6-4430-a069-9146aea02a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25946213826560355"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab259c5-ef01-4686-a5f6-def37909e00c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54138145-5c3e-4ff6-a09b-c9240ffcbb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
