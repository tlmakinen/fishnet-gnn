{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "QJkKHBn_Hlun",
   "metadata": {
    "id": "QJkKHBn_Hlun"
   },
   "source": [
    "#### 1. Setup: Install and Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ii6YddX0ybeC",
   "metadata": {
    "id": "ii6YddX0ybeC"
   },
   "source": [
    "First we need to install the libraries we will be using for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bm0zwUuwyBRg",
   "metadata": {
    "id": "bm0zwUuwyBRg"
   },
   "source": [
    "Next we import these libraries. We are going to use PyTorch Geometrics Data, Dataset and DataLoader objects to process our data. We will then convert the dataset to a Jraph GraphsTuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba5894e-d6bc-41de-ad9f-d30727282f51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ba5894e-d6bc-41de-ad9f-d30727282f51",
    "outputId": "e9e27143-e35a-40b8-86ba-6528eea9ebb8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import functools\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "import jraph\n",
    "import flax\n",
    "import haiku as hk\n",
    "import optax\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from ogb.nodeproppred import Evaluator, PygNodePropPredDataset\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import pathlib\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TTb6zXD4Idvu",
   "metadata": {
    "id": "TTb6zXD4Idvu"
   },
   "source": [
    "#### 2. Download dataset from PyTorch Geometrics Common Benchmark Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urtjALT2scZ_",
   "metadata": {
    "id": "urtjALT2scZ_"
   },
   "outputs": [],
   "source": [
    "# from ogb.nodeproppred import NodePropPredDataset\n",
    "\n",
    "# d_name = 'ogbn-proteins'\n",
    "\n",
    "# dataset = NodePropPredDataset(name = d_name)\n",
    "\n",
    "# split_idx = dataset.get_idx_split()\n",
    "# train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "# graph, label = dataset[0] # graph: library-agnostic graph object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gei7y_Do_tYu",
   "metadata": {
    "id": "gei7y_Do_tYu",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/proteins.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.21 GB: 100%|██████████| 216/216 [00:59<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/proteins.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2935.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "dataset = PygNodePropPredDataset(name = 'ogbn-proteins')\n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "\n",
    "\n",
    "data = dataset[0] # pyg graph object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "FxeXDi6hAmtt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxeXDi6hAmtt",
    "outputId": "8820ea52-1c0f-4c42-96d9-1bba959e811f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = PygNodePropPredDataset(name = 'ogbn-proteins', root='/data101/makinen/ogbn/')\n",
    "splitted_idx = dataset.get_idx_split()\n",
    "data = dataset[0]\n",
    "data.node_species = None\n",
    "data.y = data.y.to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gxqxWDhiKJcg",
   "metadata": {
    "id": "gxqxWDhiKJcg",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=132534, edge_index=[2, 79122504], edge_attr=[79122504, 8], y=[132534, 112])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nPF7Uwl_B8EG",
   "metadata": {
    "id": "nPF7Uwl_B8EG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import RandomNodeLoader\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "\n",
    "row, col = data.edge_index\n",
    "data.x = scatter(data.edge_attr, col, dim_size=data.num_nodes, reduce='sum')\n",
    "\n",
    "# Set split indices to masks.\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    mask[splitted_idx[split]] = True\n",
    "    data[f'{split}_mask'] = mask\n",
    "\n",
    "train_reader = RandomNodeLoader(data, num_parts=200, shuffle=True,\n",
    "                                num_workers=0)\n",
    "test_reader = RandomNodeLoader(data, num_parts=5, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "BcfLG2dieqyJ",
   "metadata": {
    "collapsed": true,
    "id": "BcfLG2dieqyJ",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([663, 8])\n",
      "tensor(430)\n",
      "torch.Size([663, 8])\n",
      "tensor(432)\n",
      "torch.Size([663, 8])\n",
      "tensor(444)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m train_reader:\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;28mprint\u001b[39m(d\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28mprint\u001b[39m(d\u001b[38;5;241m.\u001b[39mtrain_mask\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch_geometric/loader/random_node_loader.py:61\u001b[0m, in \u001b[0;36mRandomNodeLoader.collate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     58\u001b[0m     index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(index)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, Data):\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, HeteroData):\n\u001b[1;32m     64\u001b[0m     node_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     65\u001b[0m         key: index[(index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m start) \u001b[38;5;241m&\u001b[39m (index \u001b[38;5;241m<\u001b[39m end)] \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, (start, end) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     67\u001b[0m     }\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch_geometric/data/data.py:614\u001b[0m, in \u001b[0;36mData.subgraph\u001b[0;34m(self, subset)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_edge_attr(key):\n\u001b[1;32m    613\u001b[0m         cat_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__cat_dim__(key, value)\n\u001b[0;32m--> 614\u001b[0m         data[key] \u001b[38;5;241m=\u001b[39m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch_geometric/utils/select.py:21\u001b[0m, in \u001b[0;36mselect\u001b[0;34m(src, index_or_mask, dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(src, Tensor):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index_or_mask\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbool:\n\u001b[0;32m---> 21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmask_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_or_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(dim, index_or_mask)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(src, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch_geometric/utils/mask.py:25\u001b[0m, in \u001b[0;36mmask_select\u001b[0;34m(src, dim, mask)\u001b[0m\n\u001b[1;32m     22\u001b[0m size \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m src\u001b[38;5;241m.\u001b[39mdim()\n\u001b[1;32m     23\u001b[0m size[dim] \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[0;32m---> 25\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(src\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     28\u001b[0m size[dim] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for d in train_reader:\n",
    "  print(d.x.shape)\n",
    "  print(d.train_mask.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EvvhPnbw25To",
   "metadata": {
    "id": "EvvhPnbw25To"
   },
   "source": [
    "Next we split the toy data and apply it to our Custom dataset class. The class returns one graph sample as a Pytorch Geometric Data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "DbuZFkvbBHBR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbuZFkvbBHBR",
    "outputId": "46d168ea-4158-48f8-f89c-b285daca3440",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132534, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kYM50bfZ5tui",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYM50bfZ5tui",
    "outputId": "44881c5d-c9d8-4f1c-8213-39b0a2f679ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.99215449607725"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "132534 / 3314"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t52jBCMYQFu5",
   "metadata": {
    "id": "t52jBCMYQFu5"
   },
   "source": [
    "#### 4. [Optional]: Add Graph Padding to Speed Up Training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hp64aqz31BSp",
   "metadata": {
    "id": "hp64aqz31BSp"
   },
   "source": [
    "As Jax recompiles the program for each graph size, padding the number of nodes and edges in the graph to the nearest power of two can speed up training. See this [tutorial](https://colab.research.google.com/github/deepmind/educational/blob/master/colabs/summer_schools/intro_to_graph_nets_tutorial_with_jraph.ipynb#scrollTo=lGhnsIovZQpo) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f7ea73-f144-44f0-b2e2-01dbafc0acba",
   "metadata": {
    "id": "f6f7ea73-f144-44f0-b2e2-01dbafc0acba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/ogb_examples/train.py\n",
    "def _nearest_bigger_power_of_two(x: int) -> int:\n",
    "    \"\"\"Computes the nearest power of two greater than x for padding.\"\"\"\n",
    "    y = 2\n",
    "    while y < x:\n",
    "        y *= 2\n",
    "    return y\n",
    "\n",
    "def pad_graph_to_nearest_power_of_two(graphs_tuple: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "    \"\"\"Pads a batched `GraphsTuple` to the nearest power of two.\n",
    "\n",
    "    For example, if a `GraphsTuple` has 7 nodes, 5 edges and 3 graphs, this method\n",
    "    would pad the `GraphsTuple` nodes and edges:\n",
    "        7batch_sizedes --> 8 nodes (2^3)\n",
    "        5 edges --> 8 edges (2^3)\n",
    "\n",
    "    And since padding is accomplished using `jraph.pad_with_graphs`, an extra\n",
    "    graph and node is added:\n",
    "        8 nodes --> 9 nodes\n",
    "        3 graphs --> 4 graphs\n",
    "\n",
    "    Args:\n",
    "        graphs_tuple: a batched `GraphsTuple` (can be batch size 1).\n",
    "\n",
    "    Returns:\n",
    "        A graphs_tuple batched to the nearest power of two.\n",
    "    \"\"\"\n",
    "    # Add 1 since we need at least one padding node for pad_with_graphs.\n",
    "    pad_nodes_to = _nearest_bigger_power_of_two(jnp.sum(graphs_tuple.n_node)) + 1\n",
    "    pad_edges_to = _nearest_bigger_power_of_two(jnp.sum(graphs_tuple.n_edge))\n",
    "    # Add 1 since we need at least one padding graph for pad_with_graphs.\n",
    "    # We do not pad to nearest power of two because the batch size is fixed.\n",
    "    pad_graphs_to = graphs_tuple.n_node.shape[0] + 1\n",
    "    return jraph.pad_with_graphs(graphs_tuple, pad_nodes_to, pad_edges_to,\n",
    "                               pad_graphs_to)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-35rkaW51vY6",
   "metadata": {
    "id": "-35rkaW51vY6"
   },
   "source": [
    "#### 5. Convert the PyTorch Geometric Object to a Jraph GraphsTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iYcmelcdSCII",
   "metadata": {
    "id": "iYcmelcdSCII"
   },
   "source": [
    "[link text](https://)Finally we will convert the PyTorch Geometric Data object to a Jraph GraphsTuple. The function written below should be called in your training loop after loading the batch data. The function also pads the whole batch graphs once and returns padded batch GraphsTuple.\n",
    "\n",
    "\n",
    "# SET THE MODE TO TRAIN OR VALID !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "zVQCx7il7WU9",
   "metadata": {
    "collapsed": true,
    "id": "zVQCx7il7WU9",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(num_nodes=884, edge_index=[2, 3824], edge_attr=[3824, 8], y=[884, 112], x=[884, 8], train_mask=[884], valid_mask=[884], test_mask=[884])\n",
      "Data(num_nodes=884, edge_index=[2, 3094], edge_attr=[3094, 8], y=[884, 112], x=[884, 8], train_mask=[884], valid_mask=[884], test_mask=[884])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_reader):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;28mprint\u001b[39m(d)\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch_geometric/loader/random_node_loader.py:61\u001b[0m, in \u001b[0;36mRandomNodeLoader.collate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     58\u001b[0m     index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(index)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, Data):\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, HeteroData):\n\u001b[1;32m     64\u001b[0m     node_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     65\u001b[0m         key: index[(index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m start) \u001b[38;5;241m&\u001b[39m (index \u001b[38;5;241m<\u001b[39m end)] \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, (start, end) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     67\u001b[0m     }\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch_geometric/data/data.py:614\u001b[0m, in \u001b[0;36mData.subgraph\u001b[0;34m(self, subset)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_edge_attr(key):\n\u001b[1;32m    613\u001b[0m         cat_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__cat_dim__(key, value)\n\u001b[0;32m--> 614\u001b[0m         data[key] \u001b[38;5;241m=\u001b[39m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch_geometric/utils/select.py:21\u001b[0m, in \u001b[0;36mselect\u001b[0;34m(src, index_or_mask, dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(src, Tensor):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index_or_mask\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbool:\n\u001b[0;32m---> 21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmask_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_or_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(dim, index_or_mask)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(src, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n",
      "File \u001b[0;32m/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/torch_geometric/utils/mask.py:25\u001b[0m, in \u001b[0;36mmask_select\u001b[0;34m(src, dim, mask)\u001b[0m\n\u001b[1;32m     22\u001b[0m size \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m src\u001b[38;5;241m.\u001b[39mdim()\n\u001b[1;32m     23\u001b[0m size[dim] \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[0;32m---> 25\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(src\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     28\u001b[0m size[dim] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,d in enumerate(train_reader):\n",
    "  print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vO98_cWV8j7i",
   "metadata": {
    "id": "vO98_cWV8j7i",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wsD9kJENP8xb",
   "metadata": {
    "id": "wsD9kJENP8xb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_batched_padded_graph_tuples(batch, mode=\"train\", pad=False):\n",
    "\n",
    "    masks = (jnp.array(batch.train_mask), jnp.array(batch.valid_mask), jnp.array(batch.test_mask))\n",
    "\n",
    "    if mode == \"train\":\n",
    "      mask = masks[0]\n",
    "    elif mode == \"valid\":\n",
    "      mask = masks[1]\n",
    "    else:\n",
    "      mask = masks[2]\n",
    "\n",
    "\n",
    "    graphs = jraph.GraphsTuple(\n",
    "            nodes=jnp.array(batch.x),\n",
    "            edges=jnp.array(batch.edge_attr), # this particular data doesn't have edge features, hence we set to None\n",
    "            n_node=jnp.array([batch.num_nodes]),\n",
    "            n_edge=jnp.array([batch.edge_attr.shape[0]]),\n",
    "            senders=jnp.array(batch.edge_index[0, :]),\n",
    "            receivers=jnp.array(batch.edge_index[1, :]),\n",
    "            globals=None)\n",
    "\n",
    "    labels = jnp.array(batch.y)\n",
    "    if pad:\n",
    "        graphs = pad_graph_to_nearest_power_of_two(graphs) # padd the whole batch once\n",
    "    \n",
    "        # put into jnp\n",
    "        graphs = jraph.GraphsTuple(\n",
    "                nodes=jnp.array(graphs.nodes),\n",
    "                edges=jnp.array(graphs.edges), \n",
    "                n_node=jnp.array(graphs.n_node),\n",
    "                n_edge=jnp.array(graphs.n_edge),\n",
    "                senders=jnp.array(graphs.senders),\n",
    "                receivers=jnp.array(graphs.receivers),\n",
    "                globals=None)\n",
    "    \n",
    "    return graphs, labels, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jv4WAtJc4gy8",
   "metadata": {
    "id": "jv4WAtJc4gy8"
   },
   "source": [
    "#### Benchmarking the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aKuy059sP6o-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aKuy059sP6o-",
    "outputId": "3dbe43a7-5ca9-447f-d289-f85d3e6381e0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 4.81 s, total: 15.2 s\n",
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch = next(iter(train_reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37d372de-1463-43ef-bfff-a666814cf62b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37d372de-1463-43ef-bfff-a666814cf62b",
    "outputId": "c3db3a03-9c7a-4267-fa8d-7eed3774bd1f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 228 ms, sys: 327 ms, total: 555 ms\n",
      "Wall time: 427 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "graphs, labels, masks = get_batched_padded_graph_tuples(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f3c57c6-97c8-43af-a791-cf1ab4a4f313",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.0903156e+01, 4.0299836e-01, 4.0299836e-01, ..., 3.4755978e+01,\n",
       "        4.0299836e-01, 3.8805943e+01],\n",
       "       [5.7158399e+00, 2.2160218e+00, 2.3250105e+00, ..., 4.1051447e+02,\n",
       "        2.3442184e+02, 1.6764810e+02],\n",
       "       [1.2919567e+01, 1.4190103e+00, 1.4190103e+00, ..., 2.0222116e+02,\n",
       "        9.2318535e+01, 1.8551103e+02],\n",
       "       ...,\n",
       "       [3.0109994e+00, 1.1000001e-02, 1.1000001e-02, ..., 8.1799996e-01,\n",
       "        1.1000001e-02, 2.8800002e-01],\n",
       "       [1.3528005e+01, 2.8000003e-02, 2.8000003e-02, ..., 2.0300001e-01,\n",
       "        2.8000003e-02, 2.8000003e-02],\n",
       "       [4.5099998e+00, 1.0000001e-02, 1.0000001e-02, ..., 1.0000001e-02,\n",
       "        1.0000001e-02, 1.6000000e-01]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cauCnG14i3Oi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cauCnG14i3Oi",
    "outputId": "2795b2c1-df82-42e4-c8f2-a4f58970aa05",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphs:  GraphsTuple(nodes=Array([[1.0903156e+01, 4.0299836e-01, 4.0299836e-01, ..., 3.4755978e+01,\n",
      "        4.0299836e-01, 3.8805943e+01],\n",
      "       [5.7158399e+00, 2.2160218e+00, 2.3250105e+00, ..., 4.1051447e+02,\n",
      "        2.3442184e+02, 1.6764810e+02],\n",
      "       [1.2919567e+01, 1.4190103e+00, 1.4190103e+00, ..., 2.0222116e+02,\n",
      "        9.2318535e+01, 1.8551103e+02],\n",
      "       ...,\n",
      "       [3.0109994e+00, 1.1000001e-02, 1.1000001e-02, ..., 8.1799996e-01,\n",
      "        1.1000001e-02, 2.8800002e-01],\n",
      "       [1.3528005e+01, 2.8000003e-02, 2.8000003e-02, ..., 2.0300001e-01,\n",
      "        2.8000003e-02, 2.8000003e-02],\n",
      "       [4.5099998e+00, 1.0000001e-02, 1.0000001e-02, ..., 1.0000001e-02,\n",
      "        1.0000001e-02, 1.6000000e-01]], dtype=float32), edges=Array([[0.501, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
      "       [0.501, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
      "       [0.501, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
      "       ...,\n",
      "       [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.427],\n",
      "       [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
      "       [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001]], dtype=float32), receivers=Array([248,   4, 596, ..., 411, 405, 411], dtype=int32), senders=Array([  4, 248,   4, ..., 415, 411, 405], dtype=int32), globals=None, n_node=Array([663], dtype=int32), n_edge=Array([2448], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print('graphs: ', graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cCvidofo89s4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCvidofo89s4",
    "outputId": "1a7fb5a3-c3b3-4792-ed9e-ac5ccb9e0cca",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30QSMeZX8Etv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30QSMeZX8Etv",
    "outputId": "1809e4f6-a3e9-4032-a2b7-56247c9bde59",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51662, 8), (3314, 8))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs.edges.shape, graphs.nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ITUNJwOV8wCP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITUNJwOV8wCP",
    "outputId": "48f9d5f0-2da5-4244-f9f7-5c6788a47cb4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[3.8999990e-02, 3.8999990e-02, 3.8999990e-02, ..., 3.8999990e-02,\n",
       "        3.8999990e-02, 3.8999990e-02],\n",
       "       [1.9265053e+01, 6.6917572e+01, 1.7660265e+00, ..., 1.8616872e+02,\n",
       "        1.7660265e+00, 1.5972354e+02],\n",
       "       [5.8999884e-01, 9.0000004e-02, 9.0000004e-02, ..., 5.7219958e+00,\n",
       "        9.0000004e-02, 2.2717001e+01],\n",
       "       ...,\n",
       "       [5.0139995e+00, 1.4000001e-02, 1.4000001e-02, ..., 6.3400006e-01,\n",
       "        1.4000001e-02, 1.4000001e-02],\n",
       "       [1.0027004e+01, 2.7000003e-02, 2.7000003e-02, ..., 1.1300000e+00,\n",
       "        2.7000003e-02, 2.7999997e-01],\n",
       "       [7.0289984e+00, 2.9000003e-02, 2.9000003e-02, ..., 2.9000003e-02,\n",
       "        1.3529000e+01, 2.9000003e-02]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "qYDugRoJTLxb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYDugRoJTLxb",
    "outputId": "aaed6232-4fe4-4b29-ff11-b52e6a83a0b6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('labels: ', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uKvv1DI19iXD",
   "metadata": {
    "id": "uKvv1DI19iXD"
   },
   "source": [
    "# do the graphnet thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "O-daIXeC9m9D",
   "metadata": {
    "id": "O-daIXeC9m9D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(hk.Module):\n",
    "  def __init__(self, features: jnp.ndarray):\n",
    "    super().__init__()\n",
    "    self.features = features\n",
    "\n",
    "  def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "    layers = []\n",
    "    for feat in self.features[:-1]:\n",
    "      layers.append(hk.Linear(feat))\n",
    "      layers.append(jax.nn.relu)\n",
    "    layers.append(hk.Linear(self.features[-1]))\n",
    "\n",
    "    mlp = hk.Sequential(layers)\n",
    "    return mlp(x)\n",
    "\n",
    "# Use MLP block to define the update node function\n",
    "update_node_fn = lambda x: MLP(features=[8, 4])(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "iYfPjU4XTV7G",
   "metadata": {
    "id": "iYfPjU4XTV7G",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-13 22:31:21.961256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_probability.substrates.jax as tfp\n",
    "\n",
    "# custom fishnets aggregation\n",
    "\n",
    "def fill_diagonal(a, val):\n",
    "  assert a.ndim >= 2\n",
    "  i, j = jnp.diag_indices(min(a.shape[-2:]))\n",
    "  return a.at[..., i, j].set(val)\n",
    "\n",
    "def construct_fisher_matrix_multiple(outputs):\n",
    "    Q = (tfp.math.fill_triangular(outputs))\n",
    "    # vmap the jnp.diag function for the batch\n",
    "    _diag = jax.vmap(jnp.diag)\n",
    "    middle = _diag(jnp.triu(Q) - jax.nn.softplus(jnp.triu(Q)))\n",
    "    padding = jnp.zeros(Q.shape)\n",
    "\n",
    "    L = Q - fill_diagonal(padding, middle)\n",
    "\n",
    "    return jnp.einsum('...ij,...jk->...ik', L, jnp.transpose(L, (0, 2, 1)))\n",
    "\n",
    "def construct_fisher_matrix_single(outputs):\n",
    "    Q = tfp.math.fill_triangular(outputs)\n",
    "    middle = jnp.diag(jnp.triu(Q) - jax.nn.softplus(jnp.triu(Q)))\n",
    "    padding = jnp.zeros(Q.shape)\n",
    "\n",
    "    L = Q - fill_diagonal(padding, middle)\n",
    "\n",
    "    return jnp.einsum('...ij,...jk->...ik', L, jnp.transpose(L, (1, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0Q1IOsso9j3p",
   "metadata": {
    "id": "0Q1IOsso9j3p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from networkx.algorithms.clique import graph_clique_number\n",
    "#from sklearn.utils.validation import FiniteStatus\n",
    "\n",
    "import jax.tree_util as tree\n",
    "import jraph\n",
    "import flax\n",
    "import haiku as hk\n",
    "import optax\n",
    "import pickle\n",
    "import numpy as onp\n",
    "import networkx as nx\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/ogb_examples/train.py\n",
    "\n",
    "n_p = 8 # bottleneck\n",
    "n_fisher = (n_p * (n_p + 1)) // 2\n",
    "\n",
    "n_bottleneck = n_p + n_fisher\n",
    "\n",
    "n_bottleneck_nodes = 112\n",
    "\n",
    "hidden_size = 50\n",
    "\n",
    "# custom mean function for padded inputs\n",
    "def fishnets_aggregation(\n",
    "                 data: jnp.ndarray,\n",
    "                 segment_ids: jnp.ndarray,\n",
    "                 num_segments: Optional[int] = None,\n",
    "                 indices_are_sorted: bool = False,\n",
    "                 unique_indices: bool = False):\n",
    "  \"\"\"Returns mean for each segment.\n",
    "  Args:\n",
    "    n_data: the number of data we want to take the mean of\n",
    "    data: the values which are averaged segment-wise.\n",
    "    segment_ids: indices for the segments.\n",
    "    num_segments: total number of segments.\n",
    "    indices_are_sorted: whether ``segment_ids`` is known to be sorted.\n",
    "    unique_indices: whether ``segment_ids`` is known to be free of duplicates.\n",
    "  \"\"\"\n",
    "  #print(\"data\", data.shape)\n",
    "  score = data[..., :n_p]\n",
    "  fisher = data[..., n_p:]\n",
    "\n",
    "  # print(\"fisher cholesky\", fisher.shape)\n",
    "  # print(\"score\", score.shape)\n",
    "  # print(\"segment_ids\", segment_ids.shape)\n",
    "\n",
    "  score = jraph.segment_sum(\n",
    "      score,\n",
    "      segment_ids,\n",
    "      num_segments,\n",
    "      indices_are_sorted=indices_are_sorted,\n",
    "      unique_indices=unique_indices)\n",
    "\n",
    "  # construct fisher matrix\n",
    "  fisher = construct_fisher_matrix_multiple(fisher)\n",
    "\n",
    "  # should construct matrix before doing sum but let's see how this works\n",
    "  fisher = jraph.segment_sum(\n",
    "      fisher.reshape(-1, int(n_p**2)),\n",
    "      segment_ids,\n",
    "      num_segments,\n",
    "      indices_are_sorted=indices_are_sorted,\n",
    "      unique_indices=unique_indices).reshape(-1, n_p, n_p)\n",
    "\n",
    "  fisher += jnp.eye(n_p) # add prior\n",
    "  mle = jnp.einsum('...jk,...k->...j', jnp.linalg.inv(fisher), score)\n",
    "\n",
    "  return mle\n",
    "\n",
    "\n",
    "\n",
    "def fishnets_for_edges(\n",
    "                 data: jnp.ndarray,\n",
    "                 segment_ids: jnp.ndarray,\n",
    "                 num_segments: Optional[int] = None,\n",
    "                 indices_are_sorted: bool = False,\n",
    "                 unique_indices: bool = False):\n",
    "  \"\"\"Returns mean for each segment.\n",
    "  Args:\n",
    "    n_data: the number of data we want to take the mean of\n",
    "    data: the values which are averaged segment-wise.\n",
    "    segment_ids: indices for the segments.\n",
    "    num_segments: total number of segments.\n",
    "    indices_are_sorted: whether ``segment_ids`` is known to be sorted.\n",
    "    unique_indices: whether ``segment_ids`` is known to be free of duplicates.\n",
    "  \"\"\"\n",
    "  #print(\"data\", data.shape)\n",
    "  score = data[..., :n_p]\n",
    "  fisher = data[..., n_p:]\n",
    "\n",
    "  score = jraph.segment_sum(\n",
    "      score,\n",
    "      segment_ids,\n",
    "      num_segments,\n",
    "      indices_are_sorted=indices_are_sorted,\n",
    "      unique_indices=unique_indices)\n",
    "\n",
    "  # construct fisher matrix\n",
    "  fisher = construct_fisher_matrix_multiple(fisher)\n",
    "\n",
    "  # should construct matrix before doing sum but let's see how this works\n",
    "  fisher = jraph.segment_sum(\n",
    "      fisher.reshape(-1, int(n_p**2)),\n",
    "      segment_ids,\n",
    "      num_segments,\n",
    "      indices_are_sorted=indices_are_sorted,\n",
    "      unique_indices=unique_indices).reshape(-1, n_p, n_p)\n",
    "\n",
    "  fisher += jnp.eye(n_p) # add prior\n",
    "\n",
    "  mle = jnp.einsum('...jk,...k->...j', jnp.linalg.inv(fisher), score)\n",
    "\n",
    "  # concatenate fisher and output mle for loss function\n",
    "  output = jnp.concatenate([mle, fisher.reshape(-1, n_p**2)], 1)\n",
    "\n",
    " # print(\"edge aggregation output shape\", output.shape)\n",
    "\n",
    "  return output\n",
    "\n",
    "\n",
    "@jraph.concatenated_args\n",
    "def edge_update_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Edge update function for graph net.\"\"\"\n",
    "  net = hk.Sequential(\n",
    "      [hk.Linear(hidden_size), jax.nn.swish,\n",
    "       hk.Linear(hidden_size), jax.nn.swish,\n",
    "       hk.Linear(hidden_size), jax.nn.swish,\n",
    "       hk.Linear(n_bottleneck)])\n",
    "  return net(feats)\n",
    "\n",
    "# make this into a fishnets aggregation\n",
    "\n",
    "@jraph.concatenated_args\n",
    "def node_update_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "\n",
    "  #print('input to node fn', feats.shape)\n",
    "\n",
    "  net = hk.Sequential(\n",
    "      [hk.Linear(hidden_size), jax.nn.swish,\n",
    "       hk.Linear(n_bottleneck_nodes)])\n",
    "  return net(feats)\n",
    "\n",
    "@jraph.concatenated_args\n",
    "def update_global_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Global update function for graph net.\"\"\"\n",
    "  # MUTAG is a binary classification task, so output pos neg logits.\n",
    "  #print(\"global feats\", feats.shape)\n",
    "  net = hk.Sequential(\n",
    "      [hk.Linear(hidden_size), jax.nn.swish,\n",
    "       hk.Linear(2)])\n",
    "  return net(feats)\n",
    "\n",
    "@jraph.concatenated_args\n",
    "def node_fishnets_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    " #print('input to node fn', feats.shape)\n",
    "\n",
    "  # concatenated input ordering:\n",
    "  # concatenate([node, edge_sent, edge_received])\n",
    "\n",
    "  edge_feats = feats[..., n_bottleneck_nodes:]\n",
    "\n",
    "  edge_feats_receivers = edge_feats[..., :(n_p + n_p**2)]\n",
    "  edge_feats_senders =  edge_feats[..., (n_p + n_p**2):]\n",
    "  edge_feats = edge_feats_senders + edge_feats_receivers\n",
    "\n",
    "  return edge_feats\n",
    "\n",
    "\n",
    "def net_fn(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "\n",
    "\n",
    "  # Add a global paramater for graph classification.\n",
    "  graph = graph._replace(globals=None,\n",
    "                         #jnp.zeros([graph.n_node.shape[0], 1]),\n",
    "                         nodes=graph.nodes[..., n_p:],\n",
    "                         )\n",
    "\n",
    "  embedder = jraph.GraphMapFeatures(\n",
    "    embed_edge_fn=hk.Linear(hidden_size), embed_node_fn=hk.Sequential(\n",
    "      [hk.Linear(hidden_size), jax.nn.swish,\n",
    "       hk.Linear(n_bottleneck_nodes)])\n",
    "    )\n",
    "\n",
    "  graph = embedder(graph)\n",
    "\n",
    "  #print(\"pre-gnn nodes\", graph.nodes.shape)\n",
    "  #print(\"pre-gnn globals\", graph.globals)\n",
    "\n",
    "    # rho aggregation functions\n",
    "  #aggregate_nodes_for_globals_fn = lambda d,s,n: node_fishnets_fn(d,s,n) # jnp.arcsinh(jraph.segment_sum(d,s,n)) #lambda d,s,n:\n",
    "  #aggregate_edges_for_globals_fn = lambda d,s,n: fishnets_aggregation(d,s,n) # jnp.arcsinh(jraph.segment_sum(d,s,n)) #\n",
    "  aggregate_edges_for_nodes_fn = lambda d,s,n: fishnets_for_edges(d,s,n)  #lambda d,s,n: fishnets_aggregation(d,s,n) #\n",
    "\n",
    "\n",
    "  net = jraph.InteractionNetwork(\n",
    "      update_node_fn=node_update_fn,\n",
    "      update_edge_fn=edge_update_fn,\n",
    "      aggregate_edges_for_nodes_fn=aggregate_edges_for_nodes_fn,\n",
    "      include_sent_messages_in_node_update=True\n",
    "      )\n",
    "\n",
    "  graph = net(graph)\n",
    "\n",
    "  #print(\"edges\", graph.edges.shape)\n",
    "  #print(\"nodes\", graph.nodes.shape)\n",
    "\n",
    "\n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "usBjgPPWBc86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "usBjgPPWBc86",
    "outputId": "f1100c4e-feb6-44df-8fdc-59d0651aeb7f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 36, 44)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_p, n_fisher, n_bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "MavvW2y8ASkQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MavvW2y8ASkQ",
    "outputId": "c6373366-171f-46ff-97df-2ee5ca024d8b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data101/makinen/venvs/fastjax/lib/python3.9/site-packages/haiku/_src/basic.py:174: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  stddev = 1. / np.sqrt(self.input_size)\n"
     ]
    }
   ],
   "source": [
    "net = hk.without_apply_rng(hk.transform(net_fn))\n",
    "# Get a candidate graph and label to initialize the network.\n",
    "graph, labels, masks = get_batched_padded_graph_tuples(batch)\n",
    "\n",
    "# Initialize the network.\n",
    "params = net.init(jax.random.PRNGKey(42), graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6g5Q7AuHAgX8",
   "metadata": {
    "id": "6g5Q7AuHAgX8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "outgraph = net.apply(params, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88b2e9a4-0fae-4049-9d16-bb4696da5998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(663, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfV50Y-fA2E3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfV50Y-fA2E3",
    "outputId": "8d7054be-2cbe-4197-e883-36cc599229cc",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((663, 112), (2448, 44))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outgraph.nodes.shape, outgraph.edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "qBr_Vaz8951n",
   "metadata": {
    "id": "qBr_Vaz8951n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_bce_with_logits_loss(x: jnp.ndarray, y: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Computes binary cross-entropy with logits loss.\n",
    "\n",
    "  Combines sigmoid and BCE, and uses log-sum-exp trick for numerical stability.\n",
    "  See https://stackoverflow.com/a/66909858 if you want to learn more.\n",
    "\n",
    "  Args:\n",
    "    x: Predictions (logits).\n",
    "    y: Labels.\n",
    "\n",
    "  Returns:\n",
    "    Binary cross-entropy loss with mean aggregation.\n",
    "\n",
    "  \"\"\"\n",
    "  max_val = jnp.clip(x, 0, None)\n",
    "  loss = x - x * y + max_val + jnp.log(\n",
    "      jnp.exp(-max_val) + jnp.exp((-x - max_val)))\n",
    "  return loss.mean()\n",
    "\n",
    "\n",
    "def compute_loss_net(params: hk.Params, graph: jraph.GraphsTuple,\n",
    "                 labels: jnp.ndarray,\n",
    "                 net: hk.Transformed\n",
    "                 ) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "  \"\"\"Computes loss with net.\"\"\"\n",
    "\n",
    "  # APPLY NETWORK HERE\n",
    "  preds = net.apply(params, graph).nodes # extract just nodes\n",
    "\n",
    "  # do the appropriate train mask\n",
    "  loss = compute_bce_with_logits_loss(preds, labels)\n",
    "\n",
    "  return loss, preds\n",
    "\n",
    "def compute_loss(params: hk.Params, preds: jnp.ndarray,\n",
    "                 labels: jnp.ndarray,\n",
    "                 ) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "  \"\"\"Computes loss.\"\"\"\n",
    "\n",
    "  # do the appropriate train mask\n",
    "  loss = compute_bce_with_logits_loss(preds, labels)\n",
    "  return loss, preds\n",
    "\n",
    "def compute_roc_auc_score(preds: jnp.ndarray,\n",
    "                          labels: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Computes roc auc (area under the curve) score for classification.\"\"\"\n",
    "  s = jax.nn.sigmoid(preds)\n",
    "  roc_auc = roc_auc_score(labels, s)\n",
    "  return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rgWC7DZULFsp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgWC7DZULFsp",
    "outputId": "837b2ced-d02f-490e-8943-fdbd005158a9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric.loader.random_node_loader.RandomNodeLoader at 0x7fdd6217e460>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "jnQ-prMzAB-K",
   "metadata": {
    "id": "jnQ-prMzAB-K",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/ogb_examples/train.py\n",
    "def train(data_reader: Any, num_epochs: int, lr: float=1e-4) -> hk.Params:\n",
    "  \"\"\"Training loop.\"\"\"\n",
    "\n",
    "  # Transform impure `net_fn` to pure functions with hk.transform.\n",
    "  net = hk.without_apply_rng(hk.transform(net_fn))\n",
    "  # Get a candidate graph and label to initialize the network.\n",
    "  batch = next(iter(train_reader))\n",
    "\n",
    "  graph, labels, masks = get_batched_padded_graph_tuples(batch)\n",
    "\n",
    "  # Initialize the network.\n",
    "  params = net.init(jax.random.PRNGKey(42), graph)\n",
    "  # Initialize the optimizer.\n",
    "  opt_init, opt_update = optax.adam(lr)\n",
    "  opt_state = opt_init(params)\n",
    "\n",
    "  compute_loss_fn = functools.partial(compute_loss)\n",
    "\n",
    "  compute_loss_fn = jax.jit(jax.value_and_grad(\n",
    "      compute_loss_fn, has_aux=True))\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    total_loss = 0.\n",
    "    for i,batch in enumerate(data_reader):\n",
    "\n",
    "      graph, labels, masks = get_batched_padded_graph_tuples(batch)\n",
    "\n",
    "      train_mask,valid_mask,test_mask = masks # unpack masks\n",
    "\n",
    "      # apply net here and mask for training data\n",
    "      train_preds = net.apply(params, graph).nodes[train_mask]\n",
    "      train_labels = labels[train_mask]\n",
    "    \n",
    "      print(\"out nodes\", train_preds.shape)\n",
    "\n",
    "      (train_loss, train_preds), grad = compute_loss_fn(params, train_preds, train_labels)\n",
    "\n",
    "\n",
    "      updates, opt_state = opt_update(grad, opt_state, params)\n",
    "      params = optax.apply_updates(params, updates)\n",
    "\n",
    "\n",
    "#     if epoch % 10 == 0 or epoch == (num_epochs - 1):\n",
    "#       train_roc_auc = compute_roc_auc_score(train_preds, train_labels)\n",
    "\n",
    "\n",
    "#       val_loss, val_preds = compute_loss(params, graph, valid_mask, net)\n",
    "#       val_roc_auc = compute_roc_auc_score(val_preds, labels[valid_mask])\n",
    "#       print(f'epoch: {epoch}, train_loss: {train_loss:.3f}, '\n",
    "#             f'train_roc_auc: {train_roc_auc:.3f}, val_loss: {val_loss:.3f}, '\n",
    "#             f'val_roc_auc: {val_roc_auc:.3f}')\n",
    "\n",
    "\n",
    "  print('Training finished')\n",
    "  return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rqmBMB3eEK5w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rqmBMB3eEK5w",
    "outputId": "1667b699-61f9-459e-f427-3150a95f4215",
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = train(train_reader, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YGr0lKewELlv",
   "metadata": {
    "id": "YGr0lKewELlv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
